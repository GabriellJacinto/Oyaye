#!/usr/bin/env python3
"""
Test script for the complete NP-SNN model integration.

This script validates:
1. Model creation and initialization
2. Forward pass functionality
3. Gradient stability and physics constraints
4. Trajectory prediction capabilities
5. Save/load functionality
6. End-to-end pipeline integration

Tests both standard configurations and specialized variants.
"""

import torch
import numpy as np
import sys
import os

# Add src to path for imports
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from models.npsnn import (
    NPSNN, NPSNNConfig, 
    create_npsnn_for_orbital_tracking,
    create_npsnn_for_debris_tracking,
    create_minimal_npsnn
)

def test_model_creation():
    """Test different model creation methods."""
    print("üîß Testing NP-SNN model creation...")
    
    # Test factory functions
    models = {
        'orbital_tracking': create_npsnn_for_orbital_tracking(),
        'debris_tracking': create_npsnn_for_debris_tracking(),
        'minimal': create_minimal_npsnn()
    }
    
    for name, model in models.items():
        info = model.get_model_info()
        print(f"  ‚úì {name}: {info['total_parameters']} params, decoder: {info['decoder_type']}")
    
    return models

def test_forward_pass(models):
    """Test forward pass with different input configurations."""
    print("\nüöÄ Testing forward pass functionality...")
    
    for name, model in models.items():
        print(f"  Testing {name} model...")
        
        # Test single timestep
        batch_size = 4
        t = torch.randn(batch_size)
        obs = torch.randn(batch_size, model.config.obs_input_size) * 0.1
        
        try:
            outputs = model.forward(t=t, obs=obs)
            
            expected_keys = ['states', 'mem_states', 'physics_violations', 'time_features', 'snn_features']
            for key in expected_keys:
                assert key in outputs, f"Missing key: {key}"
            
            states = outputs['states']
            assert states.shape == (batch_size, model.config.decoder.state_dim), f"Wrong state shape: {states.shape}"
            
            # Check for NaN/Inf
            assert torch.isfinite(states).all(), "States contain NaN/Inf values"
            
            print(f"    ‚úì Single timestep: states {states.shape}, range: [{states.min():.3f}, {states.max():.3f}]")
            
            # Test sequential data
            seq_len = 8
            t_seq = torch.randn(batch_size, seq_len)
            obs_seq = torch.randn(batch_size, seq_len, model.config.obs_input_size) * 0.1
            
            outputs_seq = model.forward(t=t_seq, obs=obs_seq)
            states_seq = outputs_seq['states']
            
            assert states_seq.shape == (batch_size, seq_len, model.config.decoder.state_dim)
            assert torch.isfinite(states_seq).all(), "Sequential states contain NaN/Inf"
            
            print(f"    ‚úì Sequential: states {states_seq.shape}, range: [{states_seq.min():.3f}, {states_seq.max():.3f}]")
            
        except Exception as e:
            print(f"    ‚ùå Forward pass failed: {e}")
            raise

def test_gradient_stability(models):
    """Test gradient computation and stability."""
    print("\nüìä Testing gradient stability...")
    
    for name, model in models.items():
        if name == 'minimal':  # Skip minimal model (no physics)
            continue
            
        print(f"  Testing {name} model gradients...")
        
        # Enable gradients
        model.train()
        
        batch_size = 4
        t = torch.randn(batch_size, requires_grad=True)
        obs = torch.randn(batch_size, model.config.obs_input_size) * 0.1
        
        try:
            # Forward pass
            outputs = model.forward(t=t, obs=obs)
            states = outputs['states']
            
            # Compute a simple loss
            loss = torch.sum(states**2)
            
            # Backward pass
            loss.backward()
            
            # Check gradient norms
            grad_norms = []
            for param in model.parameters():
                if param.grad is not None:
                    grad_norms.append(param.grad.norm().item())
            
            max_grad_norm = max(grad_norms) if grad_norms else 0
            mean_grad_norm = np.mean(grad_norms) if grad_norms else 0
            
            print(f"    ‚úì Gradients: max={max_grad_norm:.6f}, mean={mean_grad_norm:.6f}")
            
            # Check for gradient explosion
            assert max_grad_norm < 100, f"Gradient explosion detected: {max_grad_norm}"
            
            # Test gradient clipping
            clipped_norm = model.clip_gradients(max_norm=1.0)
            print(f"    ‚úì Gradient clipping: {clipped_norm:.6f}")
            
            # Test physics-informed derivatives (if available)
            if model.config.enable_auto_diff:
                dr_dt, dv_dt = model.get_derivatives(t, obs)
                assert torch.isfinite(dr_dt).all(), "Position derivatives contain NaN/Inf"
                assert torch.isfinite(dv_dt).all(), "Velocity derivatives contain NaN/Inf"
                print(f"    ‚úì Physics derivatives: dr_dt {dr_dt.shape}, dv_dt {dv_dt.shape}")
            
        except Exception as e:
            print(f"    ‚ùå Gradient test failed: {e}")
            raise

def test_physics_constraints(models):
    """Test physics constraint enforcement."""
    print("\n‚öñÔ∏è Testing physics constraints...")
    
    for name, model in models.items():
        if not model.config.enable_physics_constraints:
            print(f"  Skipping {name} (no physics constraints)")
            continue
            
        print(f"  Testing {name} physics constraints...")
        
        batch_size = 4
        t = torch.randn(batch_size)
        obs = torch.randn(batch_size, model.config.obs_input_size) * 0.1
        
        try:
            outputs = model.forward(t=t, obs=obs)
            states = outputs['states']
            physics_violations = outputs['physics_violations']
            
            # Extract orbital elements
            positions = states[:, :3]  # (batch, 3)
            velocities = states[:, 3:6]  # (batch, 3)
            
            # Check position bounds (reasonable orbital distances)
            # Note: With small initialization and scaling, initial outputs may be near zero
            distances = torch.norm(positions, dim=1)
            earth_radius = 6.371e6
            
            # For testing purposes, check that we get finite values
            assert torch.isfinite(distances).all(), "Position distances contain NaN/Inf"
            
            # If positions are very small (due to initialization), skip detailed physics checks
            if distances.max() < 1e3:  # Less than 1 km
                print(f"    ‚ö†Ô∏è  Positions very small (max: {distances.max():.1f}m) - likely due to small initialization")
            else:
                assert (distances > earth_radius * 0.1).all(), f"Positions unreasonably close to Earth: min={distances.min():.0f}m"
            
            # Check reasonable velocity bounds
            vel_magnitudes = torch.norm(velocities, dim=1)
            assert torch.isfinite(vel_magnitudes).all(), "Velocity magnitudes contain NaN/Inf"
            
            # For reasonable velocities, check bounds (but allow small values during testing)
            if vel_magnitudes.max() > 1.0:  # If we have reasonable velocities
                assert (vel_magnitudes < 20000).all(), f"Velocities too high: max={vel_magnitudes.max():.0f}m/s"
            else:
                print(f"    ‚ö†Ô∏è  Velocities very small (max: {vel_magnitudes.max():.3f}m/s) - likely due to small initialization")
            
            # Check physics violation metrics
            if physics_violations:
                for key, value in physics_violations.items():
                    print(f"    Physics {key}: {value.item():.6f}")
            
            print(f"    ‚úì Position range: [{distances.min():.0f}, {distances.max():.0f}]m")
            print(f"    ‚úì Velocity range: [{vel_magnitudes.min():.0f}, {vel_magnitudes.max():.0f}]m/s")
            
        except Exception as e:
            print(f"    ‚ùå Physics constraint test failed: {e}")
            raise

def test_trajectory_prediction(models):
    """Test trajectory prediction capabilities."""
    print("\nüõ∞Ô∏è Testing trajectory prediction...")
    
    for name, model in models.items():
        print(f"  Testing {name} trajectory prediction...")
        
        # Create time span (1 hour with 10 minute intervals)
        t_span = torch.linspace(0, 3600, 7)  # 1 hour in seconds
        initial_obs = torch.randn(2, model.config.obs_input_size) * 0.1  # 2 trajectories
        
        try:
            trajectory = model.predict_trajectory(
                t_span=t_span,
                initial_obs=initial_obs,
                return_uncertainty=model.config.uncertainty_quantification
            )
            
            states = trajectory['states']
            consistency = trajectory['physics_consistency']
            
            expected_shape = (2, 7, model.config.decoder.state_dim)
            assert states.shape == expected_shape, f"Wrong trajectory shape: {states.shape}"
            assert torch.isfinite(states).all(), "Trajectory contains NaN/Inf"
            
            print(f"    ‚úì Trajectory shape: {states.shape}")
            
            # Check physics consistency
            if consistency:
                energy_conservation = consistency.get('energy_conservation_violation', 0)
                momentum_conservation = consistency.get('angular_momentum_conservation_violation', 0)
                print(f"    ‚úì Energy conservation violation: {energy_conservation:.6f}")
                print(f"    ‚úì Momentum conservation violation: {momentum_conservation:.6f}")
            
            # Check uncertainty if available
            if 'uncertainty' in trajectory:
                uncertainty = trajectory['uncertainty']
                assert uncertainty.shape == states.shape, "Uncertainty shape mismatch"
                print(f"    ‚úì Uncertainty range: [{uncertainty.min():.6f}, {uncertainty.max():.6f}]")
            
        except Exception as e:
            print(f"    ‚ùå Trajectory prediction failed: {e}")
            raise

def test_save_load(models):
    """Test model save and load functionality."""
    print("\nüíæ Testing save/load functionality...")
    
    model = models['orbital_tracking']  # Use full-featured model
    
    try:
        # Save model
        checkpoint_path = "/tmp/test_npsnn_checkpoint.pth"
        
        model.save_checkpoint(
            checkpoint_path, 
            optimizer_state={'lr': 0.001}, 
            epoch=42,
            metrics={'loss': 0.123}
        )
        
        print(f"    ‚úì Model saved to {checkpoint_path}")
        
        # Load model
        loaded_model, checkpoint = NPSNN.load_checkpoint(checkpoint_path)
        
        print(f"    ‚úì Model loaded, epoch: {checkpoint['epoch']}")
        
        # Test loaded model functionality
        batch_size = 2
        t = torch.randn(batch_size)
        obs = torch.randn(batch_size, model.config.obs_input_size) * 0.1
        
        outputs_original = model.forward(t=t, obs=obs)
        outputs_loaded = loaded_model.forward(t=t, obs=obs)
        
        # Compare outputs (should be identical)
        state_diff = torch.abs(outputs_original['states'] - outputs_loaded['states']).max()
        assert state_diff < 1e-6, f"Loaded model outputs differ: {state_diff}"
        
        print(f"    ‚úì Loaded model outputs match original (max diff: {state_diff:.2e})")
        
        # Cleanup
        os.remove(checkpoint_path)
        
    except Exception as e:
        print(f"    ‚ùå Save/load test failed: {e}")
        raise

def test_physics_informed_loss(models):
    """Test physics-informed loss computation."""
    print("\nüî¨ Testing physics-informed loss...")
    
    for name, model in models.items():
        if not model.config.enable_auto_diff:
            print(f"  Skipping {name} (auto-diff disabled)")
            continue
            
        print(f"  Testing {name} physics-informed loss...")
        
        batch_size = 4
        t = torch.randn(batch_size, requires_grad=True)
        obs = torch.randn(batch_size, model.config.obs_input_size) * 0.1
        
        # Create synthetic ground truth
        true_states = torch.randn(batch_size, model.config.decoder.state_dim) * 1e6
        
        try:
            losses = model.physics_informed_loss(t=t, obs=obs, true_states=true_states)
            
            print(f"    Loss components:")
            for key, value in losses.items():
                print(f"      {key}: {value.item():.6f}")
            
            # Check all losses are finite
            for key, value in losses.items():
                assert torch.isfinite(value), f"Loss {key} is not finite: {value}"
            
            print(f"    ‚úì All {len(losses)} loss components finite")
            
        except Exception as e:
            print(f"    ‚ùå Physics loss test failed: {e}")
            raise

def main():
    """Run comprehensive NP-SNN tests."""
    print("üß™ Comprehensive NP-SNN Integration Test")
    print("=" * 50)
    
    try:
        # Create models
        models = test_model_creation()
        
        # Test core functionality
        test_forward_pass(models)
        test_gradient_stability(models)
        test_physics_constraints(models)
        test_trajectory_prediction(models)
        test_save_load(models)
        test_physics_informed_loss(models)
        
        print("\nüéâ All tests passed! NP-SNN integration successful.")
        
        # Print summary
        print("\nüìã Model Summary:")
        model = models['orbital_tracking']
        info = model.get_model_info()
        print(f"  Total parameters: {info['total_parameters']:,}")
        print(f"  Memory usage: {info['memory_usage_mb']:.1f} MB")
        print(f"  Decoder type: {info['decoder_type']}")
        print(f"  Physics constraints: {model.config.enable_physics_constraints}")
        print(f"  Uncertainty quantification: {model.config.uncertainty_quantification}")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)