# NP-SNN: Neural Physics-Informed Spiking Neural Networks for Space Debris Tracking

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![MLflow](https://img.shields.io/badge/mlflow-tracking-blue)](https://mlflow.org)
[![Tests](https://img.shields.io/badge/tests-pytest-green.svg)](tests/)

**Advanced neural physics-informed spiking neural network system for space debris detection, tracking, and orbital trajectory prediction combining neuromorphic computing with physics-informed machine learning.**

## ğŸš€ Project Overview

This project implements a novel **NP-SNN (Neural Physics-Informed Spiking Neural Network)** architecture for space debris detection and tracking. The system combines:

- **Spiking Neural Networks (SNN)** for neuromorphic, event-driven sensor processing
- **Physics-Informed Neural Networks (PINN)** with orbital mechanics constraints  
- **High-fidelity orbital propagation** with J2, atmospheric drag, and solar radiation pressure
- **Multi-sensor fusion** (optical angles, radar range/Doppler, imaging)
- **Uncertainty quantification** with aleatoric and epistemic uncertainty estimation
- **Hybrid filtering** integration with EKF/UKF/Particle filters

## âœ¨ Key Features

### ğŸ§  Neural Architecture
- **Time-encoding layers** with Fourier features and learned temporal representations
- **Multi-layer SNN core** using LIF neurons with surrogate gradient training
- **Physics-constrained decoders** outputting continuous orbital states (r, v)
- **Uncertainty quantification** with probabilistic and multi-head decoders

### ğŸ›°ï¸ Orbital Mechanics
- **High-fidelity propagation** with numerical integration (RK45)
- **Realistic perturbations**: J2/J3/J4 harmonics, atmospheric drag (NRLMSISE-00), SRP
- **Energy and angular momentum conservation** constraints in loss functions
- **Multi-object scaling** with shared models and object-specific embeddings

### ğŸ“¡ Sensor Modeling  
- **Optical telescopes**: RA/Dec angles with realistic noise and visibility constraints
- **Radar systems**: Range/Doppler with beam patterns and detection thresholds
- **Event-based cameras**: Future integration for neuromorphic sensing
- **Domain randomization**: Sensor biases, noise correlation, missed detections

### ğŸ¯ Training & Evaluation
- **Curriculum learning**: Supervised pretraining â†’ mixed physics â†’ physics-dominant
- **Dynamic loss balancing** with learnable uncertainty weighting
- **MLflow experiment tracking** with full reproducibility (configs, seeds, artifacts)
- **Comprehensive benchmarking** against SGP4, EKF, UKF baselines

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dataset       â”‚    â”‚   Time Encoding  â”‚    â”‚   SNN Core      â”‚
â”‚   Generation    â”‚â”€â”€â”€â–¶â”‚   (Fourier/MLP)  â”‚â”€â”€â”€â–¶â”‚   (LIF Layers)  â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Physics       â”‚    â”‚   Decoder        â”‚    â”‚   Hybrid        â”‚
â”‚   Propagation   â”‚â—€â”€â”€â”€â”‚   (State + Ïƒ)    â”‚â”€â”€â”€â–¶â”‚   Filtering     â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Project Structure

```
Oyaye/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ space_debris_simulation.yaml    # Configuration parameters
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ generators.py              # Scenario generation & sampling
â”‚   â”‚   â”œâ”€â”€ sensors.py                 # Optical/radar/imaging simulation
â”‚   â”‚   â””â”€â”€ io.py                      # Dataset I/O utilities
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ time_encoding.py           # Fourier/learned time features
â”‚   â”‚   â”œâ”€â”€ snn_core.py                # LIF/RLIF neuron layers
â”‚   â”‚   â”œâ”€â”€ decoder.py                 # MLP decoders + uncertainty
â”‚   â”‚   â””â”€â”€ npsnn.py                   # Full NP-SNN model
â”‚   â”œâ”€â”€ physics/
â”‚   â”‚   â”œâ”€â”€ propagators.py             # Numerical orbital propagation
â”‚   â”‚   â””â”€â”€ accel_models.py            # Force models (J2, drag, SRP)
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ train_loop.py              # Curriculum training pipeline
â”‚   â”‚   â”œâ”€â”€ losses.py                  # Physics-informed loss functions
â”‚   â”‚   â””â”€â”€ schedule.py                # Learning rate & loss scheduling
â”‚   â”œâ”€â”€ eval/
â”‚   â”‚   â”œâ”€â”€ metrics.py                 # Evaluation metrics (RMSE, energy drift)
â”‚   â”‚   â””â”€â”€ benchmarks.py              # Baseline comparisons
â”‚   â””â”€â”€ infra/
â”‚       â”œâ”€â”€ mlflow_logger.py           # Experiment tracking
â”‚       â””â”€â”€ utils.py                   # Utilities & configuration
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ unit/
â”‚       â””â”€â”€ test_propagators.py        # Unit tests
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ implementation_plan.md         # Detailed implementation roadmap
â”‚   â””â”€â”€ project_proposal.md            # Project overview & motivation
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ setup.py                          # Project setup script
â””â”€â”€ README.md                         # This file
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone https://github.com/GabriellJacinto/Oyaye.git
cd Oyaye

# Set up Python environment
conda create -n npsnn-env python=3.10
conda activate npsnn-env

# Install dependencies
pip install -r requirements.txt

```

### 2. Generate Synthetic Data

```bash
# Create synthetic orbital scenarios
python -m src.data.generators --config configs/space_debris_simulation.yaml

# Generate sensor observations  
python -m src.data.sensors --scenario baseline_leo
```

### 3. Train NP-SNN Model

```bash
# Stage 1: Supervised pretraining
python -m src.train.train_loop --stage supervised --epochs 200

# Stage 2: Mixed physics training  
python -m src.train.train_loop --stage mixed --epochs 300

# Stage 3: Physics-dominant training
python -m src.train.train_loop --stage physics --epochs 500
```

### 4. Evaluate Performance

```bash
# Run comprehensive evaluation
python -m src.eval.metrics --model-path checkpoints/best_model.pt

# Compare against baselines
python -m src.eval.benchmarks --models npsnn sgp4 ekf ukf
```

### 5. View Results

```bash
# Start MLflow UI
mlflow ui --backend-store-uri ./mlruns

# Open browser to http://localhost:5000
```

## ğŸ§ª Example Usage

### Basic Training Example

```python
from src.models.npsnn import NPSNN
from src.train.train_loop import NPSNNTrainer, TrainingConfig
from src.data.generators import ScenarioGenerator

# Load configuration
config = {
    'time_encoding': {'type': 'fourier', 'dim': 64},
    'snn': {'hidden_sizes': [128, 64], 'beta': 0.9},
    'decoder': {'type': 'probabilistic', 'output_size': 6}
}

# Create model
model = NPSNN(config)

# Generate training data
generator = ScenarioGenerator(config)
train_data = generator.generate_scenarios(n_objects=100)

# Set up training
training_config = TrainingConfig(
    model_config=config,
    num_epochs=1000,
    batch_size=32,
    learning_rate=1e-3
)

trainer = NPSNNTrainer(training_config, train_data, val_data)
trainer.train()
```

### Physics-Informed Loss Example

```python
from src.train.losses import CompositeLoss

# Configure loss function
loss_config = {
    'w_measurement': 1.0,
    'w_dynamics': 3.0,
    'w_conservation': 0.1,
    'include_j2': True
}

criterion = CompositeLoss(loss_config)

# Compute loss with automatic differentiation
losses = criterion(model_outputs, batch_data)
print(f"Total loss: {losses['total_loss']:.6f}")
print(f"Dynamics residual: {losses['dynamics_loss']:.6f}")
print(f"Energy conservation: {losses['conservation_loss']:.6f}")
```

## ğŸ“Š Current Implementation Status

### âœ… Completed Components
- **Project structure and build system** - Complete modular architecture
- **Configuration management** - YAML-based config with validation
- **Orbital mechanics simulation** - Numerical propagation with J2 perturbations
- **NP-SNN model architecture** - Time encoding, SNN core, probabilistic decoders
- **Physics-informed loss functions** - Dynamics residual, conservation constraints
- **Training pipeline** - Curriculum learning with MLflow tracking
- **Evaluation metrics** - Comprehensive trajectory and physics validation
- **Testing framework** - Unit tests with pytest

### ğŸš§ In Progress
- **Advanced force models** - Atmospheric drag (NRLMSISE-00), solar radiation pressure
- **Multi-sensor fusion** - Optical + radar data integration
- **Uncertainty quantification** - Calibration and propagation validation
- **Domain randomization** - Robust training under sensor variations

### ğŸ”® Future Work
- **Real-time processing** - Optimization for operational deployment
- **Hardware acceleration** - CUDA kernels and neuromorphic chip integration
- **Multi-object scaling** - Demonstrated performance on 100+ objects
- **Production API** - RESTful service with containerization

## ğŸ”¬ Technical Details

### Physics-Informed Training
- **Automatic differentiation** for computing dr/dt and dv/dt from neural network outputs
- **Collocation points** between observations for physics residual evaluation
- **Conservation constraints** with soft penalty terms for energy and angular momentum
- **Dynamic loss balancing** using learnable uncertainty parameters

### Neuromorphic Integration
- **Surrogate gradients** for SNN backpropagation (fast sigmoid, piecewise linear)
- **Membrane potential normalization** for training stability
- **Temporal dynamics** preserved through recurrent connections
- **Event-driven processing** for future integration with neuromorphic cameras

## ğŸ§ª Testing & Validation

Run the test suite:

```bash
# All tests
pytest tests/ -v

# Specific modules
pytest tests/unit/test_propagators.py -v
pytest tests/unit/test_time_encoding.py -v
```

## ğŸ“š Documentation

- **[Project Proposal](docs/project_proposal.md)**: Scientific motivation and overview
- **Configuration Reference**: Complete parameter documentation in YAML files
- **API Documentation**: Generated from comprehensive docstrings

## ğŸ¤ Contributing

Contributions welcome! Please:

1. **Fork the repository** and create a feature branch
2. **Follow code style** (black, flake8, mypy)
3. **Add tests** for new functionality  
4. **Update documentation** including docstrings
5. **Submit pull request** with detailed description

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ† Citation

If you use this work in your research, please cite:

```bibtex
@software{oyaye2025,
  title={OYAYE: A Hybrid PINNâ€“SNN Framework for Energy-Efficient Space Situational Awareness},
  year={2025},
  url={https://github.com/GabriellJacinto/Oyaye}
}
```
